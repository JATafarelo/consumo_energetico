{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc8ae76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c69cd239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho do banco\n",
    "db_path = \"../../../data/duckdb/database.duckdb\"\n",
    "\n",
    "# Conexão com o banco DuckDB\n",
    "con = duckdb.connect(db_path)\n",
    "\n",
    "# Carrega os dados da camada bronze\n",
    "df = con.execute(\"\"\"\n",
    "    SELECT \n",
    "          CG.*\n",
    "        , CC.cluster\n",
    "                 \n",
    "    FROM gold.consumo_geral AS CG\n",
    "    \n",
    "    INNER JOIN output.clusterizacao_cliente AS CC ON\n",
    "        CG.client_id = CC.client_id\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d3d1b8",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec3175ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_lag_features(df: pd.DataFrame, coluna_alvo: str, num_lags: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gera lag features para a coluna alvo em um DataFrame.\n",
    "\n",
    "    Parâmetros:\n",
    "    df (pd.DataFrame): DataFrame original.\n",
    "    coluna_alvo (str): Nome da coluna alvo para gerar os lags.\n",
    "    num_lags (int): Quantidade de lags a serem geradas (ex: 12 gera lag_1 até lag_12).\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: DataFrame com as novas colunas de lag adicionadas.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        df_copy[f'{coluna_alvo}_lag_{lag}'] = df_copy[coluna_alvo].shift(lag)\n",
    "    return df_copy\n",
    "\n",
    "def criar_features_climaticas(df):\n",
    "    \"\"\"\n",
    "    Cria colunas de amplitude térmica, faixa de temperatura e faixa de umidade em um DataFrame.\n",
    "\n",
    "    Espera que o DataFrame tenha colunas:\n",
    "        - temperature_max\n",
    "        - temperature_min\n",
    "        - temperature\n",
    "        - humidity\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df['temperature_max'] = df['temperature'].max()\n",
    "    df['temperature_min'] = df['temperature'].min()\n",
    "\n",
    "    # Amplitude térmica\n",
    "    df['amplitude_termica'] = df['temperature_max'] - df['temperature_min']\n",
    "\n",
    "    # Faixa de temperatura média\n",
    "    def classificar_temp(temp):\n",
    "        if temp < 24.356250:\n",
    "            return 'baixa'\n",
    "        elif temp <= 25.813333:\n",
    "            return 'media'\n",
    "        else:\n",
    "            return 'alta'\n",
    "\n",
    "    df['faixa_temperatura'] = df['temperature'].apply(classificar_temp)\n",
    "\n",
    "    # Faixa de umidade\n",
    "    def classificar_umidade(h):\n",
    "        if h < 58.623529:\n",
    "            return 'baixa'\n",
    "        elif h <= 61.540625:\n",
    "            return 'media'\n",
    "        else:\n",
    "            return 'alta'\n",
    "\n",
    "    df['faixa_umidade'] = df['humidity'].apply(classificar_umidade)\n",
    "\n",
    "    return df\n",
    "\n",
    "def criar_features_clientes(df):\n",
    "    \"\"\"\n",
    "    Espera DataFrame com colunas: client_id, date (datetime) e consumption_kwh.\n",
    "    Retorna um novo DataFrame com client_id, variabilidade_consumo_cliente e tendencia_consumo_cliente.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['date_ordinal'] = df['date'].apply(lambda x: x.toordinal())  # Facilita a regressão linear\n",
    "    \n",
    "    resultados = []\n",
    "\n",
    "    for client, grupo in df.groupby('client_id'):\n",
    "        # Variabilidade do consumo\n",
    "        variabilidade = grupo['consumption_kwh'].std()\n",
    "\n",
    "        # Tendência (regressão linear)\n",
    "        if len(grupo) >= 2:\n",
    "            X = grupo[['date_ordinal']]\n",
    "            y = grupo['consumption_kwh']\n",
    "            modelo = LinearRegression().fit(X, y)\n",
    "            tendencia = modelo.coef_[0]  # Inclinação da reta\n",
    "        else:\n",
    "            tendencia = np.nan\n",
    "\n",
    "        resultados.append({\n",
    "            'client_id': client,\n",
    "            'variabilidade_consumo_cliente': variabilidade,\n",
    "            'tendencia_consumo_cliente': tendencia\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4b80f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = criar_features_climaticas(df)\n",
    "\n",
    "# 1. Geração das features por cliente\n",
    "df_features_clientes = criar_features_clientes(df)\n",
    "\n",
    "# 2. Merge com o dataframe original de consumo\n",
    "df = df.merge(\n",
    "    df_features_clientes,\n",
    "    on='client_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c20d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "faixa_temperatura = [f'temperatura_{temp}' for temp in df['faixa_temperatura'].unique().tolist()]\n",
    "\n",
    "# Codificação da variável categórica\n",
    "df = pd.get_dummies(df, columns=['faixa_temperatura'], prefix='temperatura', prefix_sep='_')\n",
    "\n",
    "df[faixa_temperatura] = df[faixa_temperatura].astype(int)\n",
    "\n",
    "faixa_umidade = [f'umidade_{temp}' for temp in df['faixa_umidade'].unique().tolist()]\n",
    "\n",
    "# Codificação da variável categórica\n",
    "df = pd.get_dummies(df, columns=['faixa_umidade'], prefix='umidade', prefix_sep='_')\n",
    "\n",
    "df[faixa_umidade] = df[faixa_umidade].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39e46a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gerar_lag_features(df, 'temperature', 14)\n",
    "df = gerar_lag_features(df, 'humidity', 14)\n",
    "df = gerar_lag_features(df, 'consumption_kwh', 14)\n",
    "\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a730b2a",
   "metadata": {},
   "source": [
    "# Treinamento de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd84b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calcular_metricas(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    nrmse = rmse / np.mean(y_true)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, nrmse, r2\n",
    "\n",
    "def treinar_modelos_xgb_por_grupo_cv(df, features):\n",
    "    df = df.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.set_index('date', inplace=True)\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    grupos = df.groupby(['cluster', 'region'])\n",
    "\n",
    "    for (cluster, region), grupo_df in grupos:\n",
    "        print(f\"\\nTreinando modelo para Cluster {cluster} - Região {region}\")\n",
    "\n",
    "        X = grupo_df[features]\n",
    "        y = grupo_df['consumption_kwh']\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "        maes, rmses, nrmses, r2s = [], [], [], []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            model = xgb.XGBRegressor(\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=3,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "\n",
    "            mae, rmse, nrmse, r2 = calcular_metricas(y_val, y_pred)\n",
    "            maes.append(mae)\n",
    "            rmses.append(rmse)\n",
    "            nrmses.append(nrmse)\n",
    "            r2s.append(r2)\n",
    "\n",
    "        # Salvar o modelo final com todos os dados\n",
    "        modelo_final = xgb.XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=3,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        modelo_final.fit(X, y)\n",
    "\n",
    "        resultados.append({\n",
    "            'cluster': cluster,\n",
    "            'region': region,\n",
    "            'mae': np.mean(maes),\n",
    "            'rmse': np.mean(rmses),\n",
    "            'nrmse': np.mean(nrmses),\n",
    "            'r2': np.mean(r2s)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce8fd4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando modelo para Cluster 0 - Região Leste\n",
      "\n",
      "Treinando modelo para Cluster 0 - Região Norte\n",
      "\n",
      "Treinando modelo para Cluster 1 - Região Centro\n",
      "\n",
      "Treinando modelo para Cluster 1 - Região Oeste\n",
      "\n",
      "Treinando modelo para Cluster 2 - Região Leste\n",
      "\n",
      "Treinando modelo para Cluster 2 - Região Norte\n",
      "\n",
      "Treinando modelo para Cluster 3 - Região Sul\n",
      "\n",
      "Treinando modelo para Cluster 4 - Região Centro\n",
      "\n",
      "Treinando modelo para Cluster 4 - Região Oeste\n",
      "  cluster  region       mae      rmse     nrmse        r2\n",
      "4       2   Leste  1.859354  2.308701  0.127443  0.121813\n",
      "3       1   Oeste  1.876553  2.332099  0.128987 -0.045969\n",
      "2       1  Centro  1.925851  2.377105  0.136699  0.007390\n",
      "5       2   Norte  1.929484  2.408688  0.141294  0.152002\n",
      "6       3     Sul  1.930882  2.425541  0.165105  0.571389\n",
      "7       4  Centro  1.859306  2.342471  0.179367  0.243962\n",
      "8       4   Oeste  1.901535  2.411506  0.183186  0.273257\n",
      "0       0   Leste  1.887039  2.350982  0.199489  0.275713\n",
      "1       0   Norte  1.858637  2.321256  0.199505  0.255679\n"
     ]
    }
   ],
   "source": [
    "# Excluir colunas que não são features\n",
    "features = [col for col in df.columns if col not in ['client_id', 'date', 'consumption_kwh', 'cluster', 'region']]\n",
    "\n",
    "# Treinar modelos\n",
    "resultados = treinar_modelos_xgb_por_grupo_cv(df, features)\n",
    "\n",
    "# Exibir resultados\n",
    "print(resultados.sort_values(by='nrmse'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfbe1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
