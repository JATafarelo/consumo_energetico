{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd51e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score,make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold,cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24550ab3",
   "metadata": {},
   "source": [
    "# Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da62581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>date</th>\n",
       "      <th>consumption_kwh</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>18.64</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>16.63</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>18.11</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>18.25</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>19.81</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>15.87</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>20.30</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-08</td>\n",
       "      <td>19.35</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>18.30</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>13.34</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  client_id       date  consumption_kwh region\n",
       "0     C0000 2023-01-01            18.64  Norte\n",
       "1     C0000 2023-01-02            16.63  Norte\n",
       "2     C0000 2023-01-03            18.11  Norte\n",
       "3     C0000 2023-01-04            18.25  Norte\n",
       "4     C0000 2023-01-05            19.81  Norte\n",
       "5     C0000 2023-01-06            15.87  Norte\n",
       "6     C0000 2023-01-07            20.30  Norte\n",
       "7     C0000 2023-01-08            19.35  Norte\n",
       "8     C0000 2023-01-09            18.30  Norte\n",
       "9     C0000 2023-01-10            13.34  Norte"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Caminho do banco\n",
    "db_path = \"../../data/duckdb/database.duckdb\"\n",
    "\n",
    "# Conexão com o banco DuckDB\n",
    "con = duckdb.connect(db_path)\n",
    "\n",
    "# Carrega os dados da camada bronze\n",
    "clientes_df = con.execute(\"SELECT * FROM silver.clientes\").df()\n",
    "consumo_df = con.execute(\"SELECT * FROM silver.consumo\").df()\n",
    "\n",
    "df = consumo_df.merge(clientes_df, on='client_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599633c",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3122349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering por client_id\n",
    "class TemporalFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # é necessário implementar os métodos fit para que o objeto possa ser usado em um pipeline\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    # o método transform define como os dados serão transformados\n",
    "    def transform(self, X):\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "        \n",
    "        df = X.copy()\n",
    "\n",
    "        # Garantir que a coluna 'date' esteja no formato datetime\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        \n",
    "        def _compute(group):\n",
    "            # Garantir a série temporal ordenada\n",
    "            ts = group.sort_values(\"date\")\n",
    "            \n",
    "\n",
    "            vals = ts[\"consumption_kwh\"].values\n",
    "            times = ts[\"date\"].astype(np.int64).values.reshape(-1, 1)\n",
    "            \n",
    "            # Calcular estatísticas básicas\n",
    "            stats = {\n",
    "                \"mean\": vals.mean(),\n",
    "                \"median\": np.median(vals),\n",
    "                \"std\": vals.std(ddof=0),\n",
    "                \"max\": vals.max(),\n",
    "                \"min\": vals.min(),\n",
    "            }\n",
    "            \n",
    "            # A regressão linear modelará a relação entre tempo e consumo de energia. O objetivo é entender como o consumo está evoluindo ao longo do tempo.\n",
    "            lr = LinearRegression().fit(times, vals)\n",
    "\n",
    "            # O slope (coeficiente angular da reta) é a taxa de variação do consumo em relação ao tempo:\n",
    "            # slope > 0 → tendência de crescimento\n",
    "            # slope < 0 → tendência de queda\n",
    "            # slope = 0 → consumo constante ao longo do tempo\n",
    "            \n",
    "            stats[\"slope\"] = lr.coef_[0]\n",
    "            \n",
    "            return pd.Series(stats)\n",
    "        \n",
    "        features = df.groupby(\"client_id\").apply(_compute).reset_index()\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4a9b50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jataf\\AppData\\Local\\Temp\\ipykernel_34568\\3221286679.py:50: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  features = df.groupby(\"client_id\").apply(_compute).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Extrair features\n",
    "fe = TemporalFeatureExtractor()\n",
    "feat_df = fe.transform(df)\n",
    "\n",
    "feat_df = feat_df.merge(clientes_df[[\"client_id\", \"region\"]], on=\"client_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d8d1c",
   "metadata": {},
   "source": [
    "# Divisão de dados para treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9feb7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = feat_df[feat_df['region'] != 'Desconhecida']\n",
    "\n",
    "proportion_list = []\n",
    "\n",
    "for region in train_df['region'].unique():\n",
    "    region_df = train_df[train_df['region'] == region]\n",
    "    \n",
    "    # cada região deve ter pelo 15 amostras, isso deixara os dados balanceados\n",
    "    proportion = region_df.sample(n=15, random_state=42)\n",
    "    proportion_list.append(proportion)\n",
    "\n",
    "train_df = pd.concat(proportion_list, ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdbd8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['client_id', 'region'])\n",
    "y_train = train_df['region']\n",
    "\n",
    "# Codificar y\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c17d4",
   "metadata": {},
   "source": [
    "# Treinamento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f989af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline base\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier())  # Placeholder que será substituído\n",
    "])\n",
    "\n",
    "# Scoring personalizado (F1-Score)\n",
    "custom_scorer = make_scorer(f1_score, average=\"weighted\")\n",
    "\n",
    "# Validação cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Grade de parâmetros\n",
    "param_grid = [\n",
    "    {\n",
    "        \"clf\": [RandomForestClassifier()],\n",
    "        \"clf__n_estimators\": [100, 200],\n",
    "        \"clf__max_depth\": [None, 10]\n",
    "    },\n",
    "    {\n",
    "        \"clf\": [xgb.XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False)],\n",
    "        \"clf__n_estimators\": [100, 200],\n",
    "        \"clf__max_depth\": [3, 6]\n",
    "    },\n",
    "    {\n",
    "        \"clf\": [lgb.LGBMClassifier()],\n",
    "        \"clf__n_estimators\": [100, 200],\n",
    "        \"clf__num_leaves\": [31, 63]\n",
    "    },\n",
    "    {\n",
    "        \"clf\": [SVC()],\n",
    "        \"clf__C\": [0.1, 1, 10],\n",
    "        \"clf__kernel\": [\"linear\", \"rbf\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# GridSearch com validação cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=custom_scorer,\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa5cc274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/26 19:32:09 INFO mlflow.tracking.fluent: Experiment with name 'modelo_classificacao_pipeline' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "2025/07/26 19:32:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/26 19:32:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Métricas de avaliação:\n",
      "Accuracy: 0.2533\n",
      "Precision: 0.2654\n",
      "Recall: 0.2533\n",
      "F1-Score: 0.2554\n",
      "ROC-AUC: 0.5491\n",
      "Confusion Matrix:\n",
      "[[2 3 6 2 2]\n",
      " [5 4 1 1 4]\n",
      " [3 2 3 1 6]\n",
      " [4 3 3 4 1]\n",
      " [4 2 1 2 6]]\n"
     ]
    }
   ],
   "source": [
    "# Define o caminho onde os dados da run serão armazenados\n",
    "mlflow.set_tracking_uri(\"../../mlruns\")\n",
    "\n",
    "# Iniciar experimento\n",
    "mlflow.set_experiment(\"modelo_classificacao_pipeline\")\n",
    "\n",
    "# Diretório onde será salvo\n",
    "local_path = \"../../models/region_classificacao/local_model\"\n",
    "\n",
    "# Verifica se a pasta existe\n",
    "if os.path.exists(local_path) and os.path.isdir(local_path):\n",
    "    # Exclui a pasta com segurança\n",
    "    shutil.rmtree(local_path)\n",
    "    \n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Executa o grid_search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predições com validação cruzada\n",
    "    y_pred = cross_val_predict(best_model, X_train, y_train, cv=cv)\n",
    "    y_proba = cross_val_predict(best_model, X_train, y_train, cv=cv, method=\"predict_proba\")\n",
    "\n",
    "    # Cálculo das métricas\n",
    "    acc = accuracy_score(y_train, y_pred)\n",
    "    prec = precision_score(y_train, y_pred, average=\"weighted\")\n",
    "    rec = recall_score(y_train, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_train, y_pred, average=\"weighted\")\n",
    "    roc = roc_auc_score(y_train, y_proba, multi_class=\"ovr\", average=\"weighted\")\n",
    "    cm = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "    # Log no MLflow\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    mlflow.log_metrics({\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1_score\": f1,\n",
    "        \"roc_auc\": roc\n",
    "    })\n",
    "\n",
    "    # Log do modelo\n",
    "    mlflow.sklearn.log_model(best_model, \"best_model\")\n",
    "    mlflow.sklearn.save_model(best_model, path=local_path)\n",
    "\n",
    "    # Log da matriz de confusão como artefato\n",
    "    np.savetxt(\"confusion_matrix.csv\", cm, delimiter=\",\")\n",
    "    mlflow.log_artifact(\"confusion_matrix.csv\")\n",
    "\n",
    "    # Log do LabelEncoder\n",
    "    label_path = \"../../models/region_classificacao/label_encoder_classificador\"\n",
    "    os.makedirs(label_path, exist_ok=True)\n",
    "    joblib.dump(label_encoder, f\"{label_path}/label_encoder.pkl\")\n",
    "    mlflow.log_artifact(f\"{label_path}/label_encoder.pkl\", artifact_path=\"label_encoder\")\n",
    "\n",
    "    # Print das métricas\n",
    "    print(\"📊 Métricas de avaliação:\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc:.4f}\")\n",
    "    print(\"Confusion Matrix:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce0ebfe",
   "metadata": {},
   "source": [
    "| Métrica             | Descrição                                                       |\n",
    "|---------------------|-----------------------------------------------------------------|\n",
    "| Acurácia            | Proporção de previsões corretas sobre o total                   |\n",
    "| Precisão            | % de verdadeiros positivos sobre todos os positivos previstos   |\n",
    "| Recall (Sensibilidade) | % de verdadeiros positivos sobre todos os reais positivos    |\n",
    "| F1-Score            | Média harmônica entre precisão e recall                         |\n",
    "| AUC-ROC             | Área sob a curva ROC, avalia separabilidade entre classes       |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
