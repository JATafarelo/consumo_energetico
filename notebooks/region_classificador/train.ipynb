{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd51e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score,make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold,cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24550ab3",
   "metadata": {},
   "source": [
    "# Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da62581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>date</th>\n",
       "      <th>consumption_kwh</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>18.64</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>16.63</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>18.11</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>18.25</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>19.81</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>15.87</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>20.30</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-08</td>\n",
       "      <td>19.35</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>18.30</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C0000</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>13.34</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  client_id       date  consumption_kwh region\n",
       "0     C0000 2023-01-01            18.64  Norte\n",
       "1     C0000 2023-01-02            16.63  Norte\n",
       "2     C0000 2023-01-03            18.11  Norte\n",
       "3     C0000 2023-01-04            18.25  Norte\n",
       "4     C0000 2023-01-05            19.81  Norte\n",
       "5     C0000 2023-01-06            15.87  Norte\n",
       "6     C0000 2023-01-07            20.30  Norte\n",
       "7     C0000 2023-01-08            19.35  Norte\n",
       "8     C0000 2023-01-09            18.30  Norte\n",
       "9     C0000 2023-01-10            13.34  Norte"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Caminho do banco\n",
    "db_path = \"../../data/duckdb/database.duckdb\"\n",
    "\n",
    "# ConexÃ£o com o banco DuckDB\n",
    "con = duckdb.connect(db_path)\n",
    "\n",
    "# Carrega os dados da camada bronze\n",
    "clientes_df = con.execute(\"SELECT * FROM silver.clientes\").df()\n",
    "consumo_df = con.execute(\"SELECT * FROM silver.consumo\").df()\n",
    "\n",
    "df = consumo_df.merge(clientes_df, on='client_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599633c",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3122349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering por client_id\n",
    "class TemporalFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # Ã© necessÃ¡rio implementar os mÃ©todos fit para que o objeto possa ser usado em um pipeline\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    # o mÃ©todo transform define como os dados serÃ£o transformados\n",
    "    def transform(self, X):\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "        \n",
    "        df = X.copy()\n",
    "\n",
    "        # Garantir que a coluna 'date' esteja no formato datetime\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        \n",
    "        def _compute(group):\n",
    "            # Garantir a sÃ©rie temporal ordenada\n",
    "            ts = group.sort_values(\"date\")\n",
    "            \n",
    "\n",
    "            vals = ts[\"consumption_kwh\"].values\n",
    "            times = ts[\"date\"].astype(np.int64).values.reshape(-1, 1)\n",
    "            \n",
    "            # Calcular estatÃ­sticas bÃ¡sicas\n",
    "            stats = {\n",
    "                \"mean\": vals.mean(),\n",
    "                \"median\": np.median(vals),\n",
    "                \"std\": vals.std(ddof=0),\n",
    "                \"max\": vals.max(),\n",
    "                \"min\": vals.min(),\n",
    "            }\n",
    "            \n",
    "            # A regressÃ£o linear modelarÃ¡ a relaÃ§Ã£o entre tempo e consumo de energia. O objetivo Ã© entender como o consumo estÃ¡ evoluindo ao longo do tempo.\n",
    "            lr = LinearRegression().fit(times, vals)\n",
    "\n",
    "            # O slope (coeficiente angular da reta) Ã© a taxa de variaÃ§Ã£o do consumo em relaÃ§Ã£o ao tempo:\n",
    "            # slope > 0 â†’ tendÃªncia de crescimento\n",
    "            # slope < 0 â†’ tendÃªncia de queda\n",
    "            # slope = 0 â†’ consumo constante ao longo do tempo\n",
    "            \n",
    "            stats[\"slope\"] = lr.coef_[0]\n",
    "            \n",
    "            return pd.Series(stats)\n",
    "        \n",
    "        features = df.groupby(\"client_id\").apply(_compute).reset_index()\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4a9b50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jataf\\AppData\\Local\\Temp\\ipykernel_34568\\3221286679.py:50: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  features = df.groupby(\"client_id\").apply(_compute).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Extrair features\n",
    "fe = TemporalFeatureExtractor()\n",
    "feat_df = fe.transform(df)\n",
    "\n",
    "feat_df = feat_df.merge(clientes_df[[\"client_id\", \"region\"]], on=\"client_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d8d1c",
   "metadata": {},
   "source": [
    "# DivisÃ£o de dados para treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9feb7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = feat_df[feat_df['region'] != 'Desconhecida']\n",
    "\n",
    "proportion_list = []\n",
    "\n",
    "for region in train_df['region'].unique():\n",
    "    region_df = train_df[train_df['region'] == region]\n",
    "    \n",
    "    # cada regiÃ£o deve ter pelo 15 amostras, isso deixara os dados balanceados\n",
    "    proportion = region_df.sample(n=15, random_state=42)\n",
    "    proportion_list.append(proportion)\n",
    "\n",
    "train_df = pd.concat(proportion_list, ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdbd8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['client_id', 'region'])\n",
    "y_train = train_df['region']\n",
    "\n",
    "# Codificar y\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c17d4",
   "metadata": {},
   "source": [
    "# Treinamento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f989af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline base\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier())  # Placeholder que serÃ¡ substituÃ­do\n",
    "])\n",
    "\n",
    "# Scoring personalizado (F1-Score)\n",
    "custom_scorer = make_scorer(f1_score, average=\"weighted\")\n",
    "\n",
    "# ValidaÃ§Ã£o cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Grade de parÃ¢metros\n",
    "param_grid = [\n",
    "    {\n",
    "        \"clf\": [RandomForestClassifier()],\n",
    "        \"clf__n_estimators\": [100, 200],\n",
    "        \"clf__max_depth\": [None, 10]\n",
    "    },\n",
    "    {\n",
    "        \"clf\": [xgb.XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False)],\n",
    "        \"clf__n_estimators\": [100, 200],\n",
    "        \"clf__max_depth\": [3, 6]\n",
    "    },\n",
    "    {\n",
    "        \"clf\": [lgb.LGBMClassifier()],\n",
    "        \"clf__n_estimators\": [100, 200],\n",
    "        \"clf__num_leaves\": [31, 63]\n",
    "    },\n",
    "    {\n",
    "        \"clf\": [SVC()],\n",
    "        \"clf__C\": [0.1, 1, 10],\n",
    "        \"clf__kernel\": [\"linear\", \"rbf\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# GridSearch com validaÃ§Ã£o cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=custom_scorer,\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa5cc274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/26 19:32:09 INFO mlflow.tracking.fluent: Experiment with name 'modelo_classificacao_pipeline' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\consumo_energetico\\venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:32:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "2025/07/26 19:32:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/26 19:32:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š MÃ©tricas de avaliaÃ§Ã£o:\n",
      "Accuracy: 0.2533\n",
      "Precision: 0.2654\n",
      "Recall: 0.2533\n",
      "F1-Score: 0.2554\n",
      "ROC-AUC: 0.5491\n",
      "Confusion Matrix:\n",
      "[[2 3 6 2 2]\n",
      " [5 4 1 1 4]\n",
      " [3 2 3 1 6]\n",
      " [4 3 3 4 1]\n",
      " [4 2 1 2 6]]\n"
     ]
    }
   ],
   "source": [
    "# Define o caminho onde os dados da run serÃ£o armazenados\n",
    "mlflow.set_tracking_uri(\"../../mlruns\")\n",
    "\n",
    "# Iniciar experimento\n",
    "mlflow.set_experiment(\"modelo_classificacao_pipeline\")\n",
    "\n",
    "# DiretÃ³rio onde serÃ¡ salvo\n",
    "local_path = \"../../models/region_classificacao/local_model\"\n",
    "\n",
    "# Verifica se a pasta existe\n",
    "if os.path.exists(local_path) and os.path.isdir(local_path):\n",
    "    # Exclui a pasta com seguranÃ§a\n",
    "    shutil.rmtree(local_path)\n",
    "    \n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Executa o grid_search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # PrediÃ§Ãµes com validaÃ§Ã£o cruzada\n",
    "    y_pred = cross_val_predict(best_model, X_train, y_train, cv=cv)\n",
    "    y_proba = cross_val_predict(best_model, X_train, y_train, cv=cv, method=\"predict_proba\")\n",
    "\n",
    "    # CÃ¡lculo das mÃ©tricas\n",
    "    acc = accuracy_score(y_train, y_pred)\n",
    "    prec = precision_score(y_train, y_pred, average=\"weighted\")\n",
    "    rec = recall_score(y_train, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_train, y_pred, average=\"weighted\")\n",
    "    roc = roc_auc_score(y_train, y_proba, multi_class=\"ovr\", average=\"weighted\")\n",
    "    cm = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "    # Log no MLflow\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    mlflow.log_metrics({\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1_score\": f1,\n",
    "        \"roc_auc\": roc\n",
    "    })\n",
    "\n",
    "    # Log do modelo\n",
    "    mlflow.sklearn.log_model(best_model, \"best_model\")\n",
    "    mlflow.sklearn.save_model(best_model, path=local_path)\n",
    "\n",
    "    # Log da matriz de confusÃ£o como artefato\n",
    "    np.savetxt(\"confusion_matrix.csv\", cm, delimiter=\",\")\n",
    "    mlflow.log_artifact(\"confusion_matrix.csv\")\n",
    "\n",
    "    # Log do LabelEncoder\n",
    "    label_path = \"../../models/region_classificacao/label_encoder_classificador\"\n",
    "    os.makedirs(label_path, exist_ok=True)\n",
    "    joblib.dump(label_encoder, f\"{label_path}/label_encoder.pkl\")\n",
    "    mlflow.log_artifact(f\"{label_path}/label_encoder.pkl\", artifact_path=\"label_encoder\")\n",
    "\n",
    "    # Print das mÃ©tricas\n",
    "    print(\"ðŸ“Š MÃ©tricas de avaliaÃ§Ã£o:\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc:.4f}\")\n",
    "    print(\"Confusion Matrix:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce0ebfe",
   "metadata": {},
   "source": [
    "| MÃ©trica             | DescriÃ§Ã£o                                                       |\n",
    "|---------------------|-----------------------------------------------------------------|\n",
    "| AcurÃ¡cia            | ProporÃ§Ã£o de previsÃµes corretas sobre o total                   |\n",
    "| PrecisÃ£o            | % de verdadeiros positivos sobre todos os positivos previstos   |\n",
    "| Recall (Sensibilidade) | % de verdadeiros positivos sobre todos os reais positivos    |\n",
    "| F1-Score            | MÃ©dia harmÃ´nica entre precisÃ£o e recall                         |\n",
    "| AUC-ROC             | Ãrea sob a curva ROC, avalia separabilidade entre classes       |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
